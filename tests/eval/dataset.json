[
  {
    "id": "q001",
    "tier": "tier_1",
    "question": "Who introduced the Transformer architecture in 'Attention Is All You Need' (2017)?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Who introduced the Transformer architecture in 'Attention Is All You Need' (2017)?",
    "expected_keywords": [
      "Vaswani",
      "Transformer",
      "2017"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q002",
    "tier": "tier_1",
    "question": "What objective is optimized during BERT pretraining?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "What objective is optimized during BERT pretraining?",
    "expected_keywords": [
      "masked language modeling",
      "next sentence prediction",
      "BERT"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q003",
    "tier": "tier_1",
    "question": "In which year was 'Deep Residual Learning for Image Recognition' published?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "In which year was 'Deep Residual Learning for Image Recognition' published?",
    "expected_keywords": [
      "2015",
      "ResNet",
      "He"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q004",
    "tier": "tier_1",
    "question": "Who are the primary authors of the original GAN paper (2014)?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Who are the primary authors of the original GAN paper (2014)?",
    "expected_keywords": [
      "Goodfellow",
      "GAN",
      "2014"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q005",
    "tier": "tier_1",
    "question": "What benchmark did AlexNet famously win in 2012?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "What benchmark did AlexNet famously win in 2012?",
    "expected_keywords": [
      "ImageNet",
      "ILSVRC",
      "AlexNet"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q006",
    "tier": "tier_1",
    "question": "What problem does the paper 'Adam: A Method for Stochastic Optimization' address?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What problem does the paper 'Adam: A Method for Stochastic Optimization' address?",
    "expected_keywords": [
      "optimization",
      "adaptive learning rate",
      "Adam"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q007",
    "tier": "tier_1",
    "question": "Who proposed the U-Net architecture and for what domain?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "Who proposed the U-Net architecture and for what domain?",
    "expected_keywords": [
      "Ronneberger",
      "biomedical image segmentation",
      "U-Net"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q008",
    "tier": "tier_1",
    "question": "What does the acronym YOLO stand for in the 2016 paper?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "What does the acronym YOLO stand for in the 2016 paper?",
    "expected_keywords": [
      "You Only Look Once",
      "object detection",
      "YOLO"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q009",
    "tier": "tier_1",
    "question": "Which paper introduced Batch Normalization and what was its core benefit?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Which paper introduced Batch Normalization and what was its core benefit?",
    "expected_keywords": [
      "Batch Normalization",
      "internal covariate shift",
      "faster training"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q010",
    "tier": "tier_1",
    "question": "What is the main contribution of the Word2Vec papers by Mikolov et al.?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "What is the main contribution of the Word2Vec papers by Mikolov et al.?",
    "expected_keywords": [
      "word embeddings",
      "skip-gram",
      "CBOW"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q011",
    "tier": "tier_1",
    "question": "In what year did the original LSTM paper appear?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "In what year did the original LSTM paper appear?",
    "expected_keywords": [
      "1997",
      "LSTM",
      "Hochreiter"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q012",
    "tier": "tier_1",
    "question": "Who introduced Dropout and why was it effective?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "Who introduced Dropout and why was it effective?",
    "expected_keywords": [
      "Srivastava",
      "regularization",
      "overfitting"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q013",
    "tier": "tier_1",
    "question": "What dataset was introduced with the MNIST paper?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What dataset was introduced with the MNIST paper?",
    "expected_keywords": [
      "MNIST",
      "handwritten digits",
      "LeCun"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q014",
    "tier": "tier_1",
    "question": "What is the central idea in 'Distilling the Knowledge in a Neural Network'?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What is the central idea in 'Distilling the Knowledge in a Neural Network'?",
    "expected_keywords": [
      "knowledge distillation",
      "teacher",
      "student"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q015",
    "tier": "tier_1",
    "question": "Who proposed Layer Normalization and for what setting was it motivated?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "Who proposed Layer Normalization and for what setting was it motivated?",
    "expected_keywords": [
      "Layer Normalization",
      "Ba",
      "recurrent neural networks"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q016",
    "tier": "tier_1",
    "question": "What was the key idea of the original seq2seq paper by Sutskever et al.?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What was the key idea of the original seq2seq paper by Sutskever et al.?",
    "expected_keywords": [
      "encoder-decoder",
      "sequence to sequence",
      "LSTM"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q017",
    "tier": "tier_1",
    "question": "What does 'Neural Machine Translation by Jointly Learning to Align and Translate' introduce?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What does 'Neural Machine Translation by Jointly Learning to Align and Translate' introduce?",
    "expected_keywords": [
      "attention mechanism",
      "Bahdanau",
      "neural machine translation"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q018",
    "tier": "tier_1",
    "question": "Who authored 'Playing Atari with Deep Reinforcement Learning'?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Who authored 'Playing Atari with Deep Reinforcement Learning'?",
    "expected_keywords": [
      "Mnih",
      "DQN",
      "Atari"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q019",
    "tier": "tier_1",
    "question": "What contribution did 'A Survey of Active Learning' (Settles, 2009) make?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What contribution did 'A Survey of Active Learning' (Settles, 2009) make?",
    "expected_keywords": [
      "active learning",
      "survey",
      "query strategies"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q020",
    "tier": "tier_1",
    "question": "What is the purpose of the BLEU metric introduced by Papineni et al. (2002)?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "What is the purpose of the BLEU metric introduced by Papineni et al. (2002)?",
    "expected_keywords": [
      "BLEU",
      "machine translation",
      "evaluation metric"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q021",
    "tier": "tier_2",
    "question": "Compare BERT and RoBERTa pretraining strategies and explain why RoBERTa improved performance.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare BERT and RoBERTa pretraining strategies and explain why RoBERTa improved performance.",
    "expected_keywords": [
      "dynamic masking",
      "next sentence prediction removed",
      "larger batches"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q022",
    "tier": "tier_2",
    "question": "How does Transformer self-attention differ from RNN-based sequence modeling in computational tradeoffs?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How does Transformer self-attention differ from RNN-based sequence modeling in computational tradeoffs?",
    "expected_keywords": [
      "parallelization",
      "path length",
      "quadratic complexity"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q023",
    "tier": "tier_2",
    "question": "Explain the difference between variational autoencoders and GANs in training objectives and output quality.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Explain the difference between variational autoencoders and GANs in training objectives and output quality.",
    "expected_keywords": [
      "ELBO",
      "adversarial loss",
      "mode collapse"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q024",
    "tier": "tier_2",
    "question": "Compare ResNet skip connections with DenseNet connectivity; when is each advantageous?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare ResNet skip connections with DenseNet connectivity; when is each advantageous?",
    "expected_keywords": [
      "residual connection",
      "feature reuse",
      "parameter efficiency"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q025",
    "tier": "tier_2",
    "question": "How does Batch Normalization differ from Layer Normalization for training stability?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How does Batch Normalization differ from Layer Normalization for training stability?",
    "expected_keywords": [
      "batch statistics",
      "sequence models",
      "normalization axis"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q026",
    "tier": "tier_2",
    "question": "Explain how Adam differs from SGD with momentum and when Adam can generalize worse.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Explain how Adam differs from SGD with momentum and when Adam can generalize worse.",
    "expected_keywords": [
      "adaptive learning rates",
      "momentum",
      "generalization gap"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q027",
    "tier": "tier_2",
    "question": "Compare GPT-style causal language modeling with BERT masked language modeling.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare GPT-style causal language modeling with BERT masked language modeling.",
    "expected_keywords": [
      "autoregressive",
      "bidirectional",
      "pretraining objective"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q028",
    "tier": "tier_2",
    "question": "How do graph neural networks (GCN) differ from graph attention networks (GAT)?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How do graph neural networks (GCN) differ from graph attention networks (GAT)?",
    "expected_keywords": [
      "message passing",
      "attention coefficients",
      "graph structure"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q029",
    "tier": "tier_2",
    "question": "Explain retrieval-augmented generation (RAG) versus pure parametric LLMs for factual QA.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Explain retrieval-augmented generation (RAG) versus pure parametric LLMs for factual QA.",
    "expected_keywords": [
      "external knowledge",
      "hallucination reduction",
      "retrieval latency"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q030",
    "tier": "tier_2",
    "question": "Compare PPO and DQN for reinforcement learning: assumptions, stability, and action spaces.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare PPO and DQN for reinforcement learning: assumptions, stability, and action spaces.",
    "expected_keywords": [
      "policy gradient",
      "value-based",
      "continuous actions"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q031",
    "tier": "tier_2",
    "question": "How does contrastive learning in SimCLR differ from supervised classification training?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How does contrastive learning in SimCLR differ from supervised classification training?",
    "expected_keywords": [
      "data augmentation",
      "positive pairs",
      "projection head"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q032",
    "tier": "tier_2",
    "question": "Explain the differences between BLEU, ROUGE, and BERTScore for text evaluation.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Explain the differences between BLEU, ROUGE, and BERTScore for text evaluation.",
    "expected_keywords": [
      "n-gram overlap",
      "recall-oriented",
      "semantic similarity"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q033",
    "tier": "tier_2",
    "question": "Compare CRF-based sequence labeling with Transformer token classification.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare CRF-based sequence labeling with Transformer token classification.",
    "expected_keywords": [
      "structured decoding",
      "label dependencies",
      "contextual embeddings"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q034",
    "tier": "tier_2",
    "question": "How do sparse attention variants like Longformer differ from full attention Transformers?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How do sparse attention variants like Longformer differ from full attention Transformers?",
    "expected_keywords": [
      "local attention",
      "linear scaling",
      "long context"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q035",
    "tier": "tier_2",
    "question": "Explain why LoRA fine-tuning is more parameter-efficient than full-model fine-tuning.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Explain why LoRA fine-tuning is more parameter-efficient than full-model fine-tuning.",
    "expected_keywords": [
      "low-rank adapters",
      "frozen weights",
      "parameter efficiency"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q036",
    "tier": "tier_2",
    "question": "Compare mixture-of-experts Transformers with dense Transformers.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare mixture-of-experts Transformers with dense Transformers.",
    "expected_keywords": [
      "routing",
      "conditional computation",
      "inference complexity"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q037",
    "tier": "tier_2",
    "question": "How does Monte Carlo dropout approximate Bayesian uncertainty estimation?",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "How does Monte Carlo dropout approximate Bayesian uncertainty estimation?",
    "expected_keywords": [
      "stochastic forward passes",
      "epistemic uncertainty",
      "approximate inference"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q038",
    "tier": "tier_2",
    "question": "Compare BM25 and dense vector retrieval for scientific search.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare BM25 and dense vector retrieval for scientific search.",
    "expected_keywords": [
      "term frequency",
      "semantic matching",
      "hybrid retrieval"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q039",
    "tier": "tier_2",
    "question": "Explain differences between chain-of-thought prompting and tool-augmented reasoning.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Explain differences between chain-of-thought prompting and tool-augmented reasoning.",
    "expected_keywords": [
      "intermediate reasoning",
      "external tools",
      "verification"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q040",
    "tier": "tier_2",
    "question": "Compare k-fold cross-validation with a single train/validation/test split in ML experiments.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare k-fold cross-validation with a single train/validation/test split in ML experiments.",
    "expected_keywords": [
      "variance reduction",
      "data efficiency",
      "computational cost"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q041",
    "tier": "tier_3",
    "question": "Synthesize findings from Transformer, BERT, and T5 papers: what scaling patterns and limitations emerge?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Synthesize findings from Transformer, BERT, and T5 papers: what scaling patterns and limitations emerge?",
    "expected_keywords": [
      "scaling",
      "pretraining",
      "compute"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q042",
    "tier": "tier_3",
    "question": "Across GAN, diffusion, and autoregressive generation papers, what open problems remain in controllability?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Across GAN, diffusion, and autoregressive generation papers, what open problems remain in controllability?",
    "expected_keywords": [
      "controllability",
      "mode coverage",
      "evaluation"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q043",
    "tier": "tier_3",
    "question": "What research gaps appear when comparing robustness papers on adversarial training and out-of-distribution detection?",
    "expected_sources": [
      "systematic_review",
      "meta_analysis",
      "policy_report"
    ],
    "difficulty": "hard",
    "query": "What research gaps appear when comparing robustness papers on adversarial training and out-of-distribution detection?",
    "expected_keywords": [
      "robustness",
      "distribution shift",
      "evaluation protocols"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q044",
    "tier": "tier_3",
    "question": "Integrate evidence from retrieval-augmented QA papers: where do current citation-grounding methods fail?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Integrate evidence from retrieval-augmented QA papers: where do current citation-grounding methods fail?",
    "expected_keywords": [
      "grounding",
      "citation quality",
      "retrieval errors"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q045",
    "tier": "tier_3",
    "question": "From RLHF and constitutional AI literature, what unresolved alignment tradeoffs are most significant?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "From RLHF and constitutional AI literature, what unresolved alignment tradeoffs are most significant?",
    "expected_keywords": [
      "alignment",
      "reward hacking",
      "oversight"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q046",
    "tier": "tier_3",
    "question": "Compare multimodal papers (CLIP, Flamingo, GPT-4V-like systems): what bottlenecks persist for reasoning?",
    "expected_sources": [
      "systematic_review",
      "meta_analysis",
      "policy_report"
    ],
    "difficulty": "hard",
    "query": "Compare multimodal papers (CLIP, Flamingo, GPT-4V-like systems): what bottlenecks persist for reasoning?",
    "expected_keywords": [
      "multimodal reasoning",
      "data quality",
      "benchmark gaps"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q047",
    "tier": "tier_3",
    "question": "Synthesize methods for efficient adaptation (adapters, LoRA, prefix tuning): what theory gaps remain?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Synthesize methods for efficient adaptation (adapters, LoRA, prefix tuning): what theory gaps remain?",
    "expected_keywords": [
      "parameter-efficient tuning",
      "transfer",
      "theoretical understanding"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q048",
    "tier": "tier_3",
    "question": "Across graph representation learning papers, what are the main limits of message-passing architectures?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Across graph representation learning papers, what are the main limits of message-passing architectures?",
    "expected_keywords": [
      "over-smoothing",
      "expressivity",
      "heterophily"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q049",
    "tier": "tier_3",
    "question": "What cross-paper evidence suggests weaknesses in current LLM evaluation benchmarks?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "What cross-paper evidence suggests weaknesses in current LLM evaluation benchmarks?",
    "expected_keywords": [
      "benchmark contamination",
      "distribution mismatch",
      "human evaluation"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q050",
    "tier": "tier_3",
    "question": "Based on reproducibility studies in ML, where should new tooling or standards focus next?",
    "expected_sources": [
      "systematic_review",
      "meta_analysis",
      "policy_report"
    ],
    "difficulty": "hard",
    "query": "Based on reproducibility studies in ML, where should new tooling or standards focus next?",
    "expected_keywords": [
      "reproducibility",
      "reporting standards",
      "open artifacts"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q051",
    "tier": "tier_1",
    "question": "Who proposed the CRISPR-Cas9 genome editing method in Science (2012)?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "easy",
    "query": "Who proposed the CRISPR-Cas9 genome editing method in Science (2012)?",
    "expected_keywords": [
      "Doudna",
      "Charpentier",
      "CRISPR-Cas9"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q052",
    "tier": "tier_1",
    "question": "In which year was the Higgs boson discovery announced by ATLAS and CMS?",
    "expected_sources": [
      "journal_article",
      "textbook",
      "conference_proceedings"
    ],
    "difficulty": "easy",
    "query": "In which year was the Higgs boson discovery announced by ATLAS and CMS?",
    "expected_keywords": [
      "2012",
      "Higgs boson",
      "CERN"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q053",
    "tier": "tier_1",
    "question": "What does PCR stand for and who developed it?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What does PCR stand for and who developed it?",
    "expected_keywords": [
      "polymerase chain reaction",
      "Kary Mullis",
      "amplification"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q054",
    "tier": "tier_1",
    "question": "Which economist introduced the concept of comparative advantage?",
    "expected_sources": [
      "working_paper",
      "government_statistics",
      "economics_journal"
    ],
    "difficulty": "easy",
    "query": "Which economist introduced the concept of comparative advantage?",
    "expected_keywords": [
      "David Ricardo",
      "comparative advantage",
      "trade"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q055",
    "tier": "tier_1",
    "question": "Who authored 'The Structure of Scientific Revolutions' and what key term did it popularize?",
    "expected_sources": [
      "primary_source_archive",
      "scholarly_monograph",
      "encyclopedia_entry"
    ],
    "difficulty": "easy",
    "query": "Who authored 'The Structure of Scientific Revolutions' and what key term did it popularize?",
    "expected_keywords": [
      "Thomas Kuhn",
      "paradigm shift",
      "scientific revolutions"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q056",
    "tier": "tier_1",
    "question": "What is the main finding of Watson and Crick's 1953 Nature paper?",
    "expected_sources": [
      "primary_source_archive",
      "scholarly_monograph",
      "encyclopedia_entry"
    ],
    "difficulty": "easy",
    "query": "What is the main finding of Watson and Crick's 1953 Nature paper?",
    "expected_keywords": [
      "DNA",
      "double helix",
      "structure"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q057",
    "tier": "tier_1",
    "question": "Which paper introduced PageRank and what system did it power?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Which paper introduced PageRank and what system did it power?",
    "expected_keywords": [
      "PageRank",
      "Brin",
      "Page"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q058",
    "tier": "tier_1",
    "question": "In what year was the first draft of the Human Genome announced?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "easy",
    "query": "In what year was the first draft of the Human Genome announced?",
    "expected_keywords": [
      "2001",
      "Human Genome Project",
      "draft sequence"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q059",
    "tier": "tier_1",
    "question": "Who introduced the K-means clustering algorithm in the Lloyd formulation?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "easy",
    "query": "Who introduced the K-means clustering algorithm in the Lloyd formulation?",
    "expected_keywords": [
      "Lloyd",
      "k-means",
      "clustering"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q060",
    "tier": "tier_1",
    "question": "What is the central result of Bell's 1964 theorem?",
    "expected_sources": [
      "journal_article",
      "textbook",
      "conference_proceedings"
    ],
    "difficulty": "easy",
    "query": "What is the central result of Bell's 1964 theorem?",
    "expected_keywords": [
      "Bell theorem",
      "local hidden variables",
      "quantum nonlocality"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q061",
    "tier": "tier_1",
    "question": "Which researcher developed prospect theory with Amos Tversky?",
    "expected_sources": [
      "peer_reviewed_journal",
      "meta_analysis",
      "methodology_handbook"
    ],
    "difficulty": "easy",
    "query": "Which researcher developed prospect theory with Amos Tversky?",
    "expected_keywords": [
      "Daniel Kahneman",
      "prospect theory",
      "decision making"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q062",
    "tier": "tier_1",
    "question": "What was the core contribution of Shannon's 1948 information theory paper?",
    "expected_sources": [
      "primary_source_archive",
      "scholarly_monograph",
      "encyclopedia_entry"
    ],
    "difficulty": "easy",
    "query": "What was the core contribution of Shannon's 1948 information theory paper?",
    "expected_keywords": [
      "entropy",
      "channel capacity",
      "communication"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q063",
    "tier": "tier_1",
    "question": "Who discovered penicillin and in what year?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "easy",
    "query": "Who discovered penicillin and in what year?",
    "expected_keywords": [
      "Alexander Fleming",
      "1928",
      "penicillin"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q064",
    "tier": "tier_1",
    "question": "What does GDP stand for and what does it measure?",
    "expected_sources": [
      "working_paper",
      "government_statistics",
      "economics_journal"
    ],
    "difficulty": "easy",
    "query": "What does GDP stand for and what does it measure?",
    "expected_keywords": [
      "gross domestic product",
      "economic output",
      "national accounts"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q065",
    "tier": "tier_1",
    "question": "Which scientist introduced natural selection in 'On the Origin of Species'?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "easy",
    "query": "Which scientist introduced natural selection in 'On the Origin of Species'?",
    "expected_keywords": [
      "Charles Darwin",
      "natural selection",
      "evolution"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q066",
    "tier": "tier_1",
    "question": "What is the purpose of the p-value in null hypothesis significance testing?",
    "expected_sources": [
      "peer_reviewed_journal",
      "meta_analysis",
      "methodology_handbook"
    ],
    "difficulty": "easy",
    "query": "What is the purpose of the p-value in null hypothesis significance testing?",
    "expected_keywords": [
      "statistical significance",
      "null hypothesis",
      "probability"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q067",
    "tier": "tier_1",
    "question": "Who introduced convolutional neural networks with LeNet-5?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "Who introduced convolutional neural networks with LeNet-5?",
    "expected_keywords": [
      "LeCun",
      "LeNet-5",
      "convolutional neural network"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q068",
    "tier": "tier_1",
    "question": "What does fMRI measure in neuroscience experiments?",
    "expected_sources": [
      "encyclopedia_entry",
      "seminal_paper",
      "official_website"
    ],
    "difficulty": "easy",
    "query": "What does fMRI measure in neuroscience experiments?",
    "expected_keywords": [
      "BOLD",
      "blood oxygen level",
      "neural activity"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q069",
    "tier": "tier_1",
    "question": "Which organization publishes the DSM-5 for psychiatric diagnosis?",
    "expected_sources": [
      "treaty_text",
      "legal_database",
      "law_review_article"
    ],
    "difficulty": "easy",
    "query": "Which organization publishes the DSM-5 for psychiatric diagnosis?",
    "expected_keywords": [
      "American Psychiatric Association",
      "DSM-5",
      "mental disorders"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q070",
    "tier": "tier_1",
    "question": "What is the main goal of the Montreal Protocol (1987)?",
    "expected_sources": [
      "treaty_text",
      "legal_database",
      "law_review_article"
    ],
    "difficulty": "easy",
    "query": "What is the main goal of the Montreal Protocol (1987)?",
    "expected_keywords": [
      "ozone layer",
      "CFCs",
      "international treaty"
    ],
    "difficulty_tier": "tier_1",
    "min_citations": 1,
    "max_citations": 3
  },
  {
    "id": "q071",
    "tier": "tier_2",
    "question": "Compare randomized controlled trials and observational cohort studies for causal inference in medicine.",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "medium",
    "query": "Compare randomized controlled trials and observational cohort studies for causal inference in medicine.",
    "expected_keywords": [
      "confounding",
      "randomization",
      "external validity"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q072",
    "tier": "tier_2",
    "question": "How do RNA-seq and microarray experiments differ in transcriptomics workflows?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "medium",
    "query": "How do RNA-seq and microarray experiments differ in transcriptomics workflows?",
    "expected_keywords": [
      "sequencing",
      "dynamic range",
      "probe-based"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q073",
    "tier": "tier_2",
    "question": "Compare finite element and finite difference methods for solving PDEs.",
    "expected_sources": [
      "journal_article",
      "textbook",
      "conference_proceedings"
    ],
    "difficulty": "medium",
    "query": "Compare finite element and finite difference methods for solving PDEs.",
    "expected_keywords": [
      "mesh",
      "discretization",
      "boundary conditions"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q074",
    "tier": "tier_2",
    "question": "How do Bayesian and frequentist approaches differ in parameter estimation?",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "How do Bayesian and frequentist approaches differ in parameter estimation?",
    "expected_keywords": [
      "prior",
      "posterior",
      "confidence interval"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q075",
    "tier": "tier_2",
    "question": "Compare CAPM and Fama-French factor models in asset pricing.",
    "expected_sources": [
      "working_paper",
      "government_statistics",
      "economics_journal"
    ],
    "difficulty": "medium",
    "query": "Compare CAPM and Fama-French factor models in asset pricing.",
    "expected_keywords": [
      "beta",
      "factors",
      "expected returns"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q076",
    "tier": "tier_2",
    "question": "Explain differences between logistic regression and probit models for binary outcomes.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Explain differences between logistic regression and probit models for binary outcomes.",
    "expected_keywords": [
      "link function",
      "latent variable",
      "maximum likelihood"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q077",
    "tier": "tier_2",
    "question": "Compare qualitative thematic analysis and grounded theory in social science research.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare qualitative thematic analysis and grounded theory in social science research.",
    "expected_keywords": [
      "coding",
      "theory generation",
      "inductive"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q078",
    "tier": "tier_2",
    "question": "How do scoping reviews differ from systematic reviews and meta-analyses?",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "How do scoping reviews differ from systematic reviews and meta-analyses?",
    "expected_keywords": [
      "breadth",
      "protocol",
      "quantitative synthesis"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q079",
    "tier": "tier_2",
    "question": "Compare PET and fMRI for measuring brain function.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare PET and fMRI for measuring brain function.",
    "expected_keywords": [
      "temporal resolution",
      "metabolic activity",
      "spatial resolution"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q080",
    "tier": "tier_2",
    "question": "How does diffraction-limit microscopy compare with super-resolution techniques like STORM?",
    "expected_sources": [
      "journal_article",
      "textbook",
      "conference_proceedings"
    ],
    "difficulty": "medium",
    "query": "How does diffraction-limit microscopy compare with super-resolution techniques like STORM?",
    "expected_keywords": [
      "diffraction limit",
      "localization",
      "nanometer resolution"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q081",
    "tier": "tier_2",
    "question": "Compare ARIMA models with LSTM models for time-series forecasting.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare ARIMA models with LSTM models for time-series forecasting.",
    "expected_keywords": [
      "stationarity",
      "sequence modeling",
      "data requirements"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q082",
    "tier": "tier_2",
    "question": "How do difference-in-differences and synthetic control methods compare for policy evaluation?",
    "expected_sources": [
      "working_paper",
      "government_statistics",
      "economics_journal"
    ],
    "difficulty": "medium",
    "query": "How do difference-in-differences and synthetic control methods compare for policy evaluation?",
    "expected_keywords": [
      "counterfactual",
      "parallel trends",
      "weighted donor pool"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q083",
    "tier": "tier_2",
    "question": "Compare grounded language model evaluation by human raters versus automated metrics.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare grounded language model evaluation by human raters versus automated metrics.",
    "expected_keywords": [
      "inter-rater reliability",
      "validity",
      "scalability"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q084",
    "tier": "tier_2",
    "question": "How does Mendelian randomization differ from traditional epidemiological association studies?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "medium",
    "query": "How does Mendelian randomization differ from traditional epidemiological association studies?",
    "expected_keywords": [
      "genetic instruments",
      "causality",
      "pleiotropy"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q085",
    "tier": "tier_2",
    "question": "Compare SIR compartmental models with agent-based models in epidemic simulation.",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "medium",
    "query": "Compare SIR compartmental models with agent-based models in epidemic simulation.",
    "expected_keywords": [
      "homogeneous mixing",
      "heterogeneity",
      "simulation"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q086",
    "tier": "tier_2",
    "question": "How do transformer-based protein language models differ from structure-based methods like AlphaFold pipelines?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "medium",
    "query": "How do transformer-based protein language models differ from structure-based methods like AlphaFold pipelines?",
    "expected_keywords": [
      "sequence embeddings",
      "structural prediction",
      "attention"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q087",
    "tier": "tier_2",
    "question": "Compare spatial autoregressive models and geographically weighted regression for spatial data.",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "Compare spatial autoregressive models and geographically weighted regression for spatial data.",
    "expected_keywords": [
      "spatial dependence",
      "local coefficients",
      "autocorrelation"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q088",
    "tier": "tier_2",
    "question": "How do principal component analysis and t-SNE differ for dimensionality reduction?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "medium",
    "query": "How do principal component analysis and t-SNE differ for dimensionality reduction?",
    "expected_keywords": [
      "linear projection",
      "nonlinear visualization",
      "variance preservation"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q089",
    "tier": "tier_2",
    "question": "Compare game-theoretic Nash equilibrium analysis with evolutionary stable strategy frameworks.",
    "expected_sources": [
      "peer_reviewed_journal",
      "systematic_review",
      "methodology_textbook"
    ],
    "difficulty": "medium",
    "query": "Compare game-theoretic Nash equilibrium analysis with evolutionary stable strategy frameworks.",
    "expected_keywords": [
      "strategic interaction",
      "dynamics",
      "stability"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q090",
    "tier": "tier_2",
    "question": "How do ethnography and survey-based methods differ in organizational behavior research?",
    "expected_sources": [
      "peer_reviewed_journal",
      "meta_analysis",
      "methodology_handbook"
    ],
    "difficulty": "medium",
    "query": "How do ethnography and survey-based methods differ in organizational behavior research?",
    "expected_keywords": [
      "participant observation",
      "self-report",
      "depth"
    ],
    "difficulty_tier": "tier_2",
    "min_citations": 2,
    "max_citations": 5
  },
  {
    "id": "q091",
    "tier": "tier_3",
    "question": "Synthesize evidence across climate attribution studies: what uncertainties remain in extreme-weather event attribution?",
    "expected_sources": [
      "systematic_review",
      "meta_analysis",
      "policy_report"
    ],
    "difficulty": "hard",
    "query": "Synthesize evidence across climate attribution studies: what uncertainties remain in extreme-weather event attribution?",
    "expected_keywords": [
      "attribution",
      "uncertainty",
      "extremes"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q092",
    "tier": "tier_3",
    "question": "Across CRISPR off-target detection papers, what methodological gaps limit clinical translation?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "hard",
    "query": "Across CRISPR off-target detection papers, what methodological gaps limit clinical translation?",
    "expected_keywords": [
      "off-target",
      "specificity",
      "safety"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q093",
    "tier": "tier_3",
    "question": "What cross-field evidence links socioeconomic inequality to health outcomes, and where are causal gaps strongest?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "hard",
    "query": "What cross-field evidence links socioeconomic inequality to health outcomes, and where are causal gaps strongest?",
    "expected_keywords": [
      "social determinants",
      "causal inference",
      "confounding"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q094",
    "tier": "tier_3",
    "question": "Integrate findings from quantum error-correction literature: what bottlenecks remain for fault-tolerant quantum computing?",
    "expected_sources": [
      "journal_article",
      "textbook",
      "conference_proceedings"
    ],
    "difficulty": "hard",
    "query": "Integrate findings from quantum error-correction literature: what bottlenecks remain for fault-tolerant quantum computing?",
    "expected_keywords": [
      "logical qubits",
      "threshold theorem",
      "overhead"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q095",
    "tier": "tier_3",
    "question": "From reproducibility audits across psychology, economics, and biomedicine, what interventions appear most effective?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "hard",
    "query": "From reproducibility audits across psychology, economics, and biomedicine, what interventions appear most effective?",
    "expected_keywords": [
      "preregistration",
      "replication",
      "statistical power"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q096",
    "tier": "tier_3",
    "question": "Synthesize evidence on AI-assisted radiology studies: where do generalization failures persist?",
    "expected_sources": [
      "peer_reviewed_journal",
      "clinical_guideline",
      "systematic_review"
    ],
    "difficulty": "hard",
    "query": "Synthesize evidence on AI-assisted radiology studies: where do generalization failures persist?",
    "expected_keywords": [
      "domain shift",
      "external validation",
      "clinician workflow"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q097",
    "tier": "tier_3",
    "question": "Across biodiversity monitoring studies, what gaps exist between remote sensing indicators and species-level outcomes?",
    "expected_sources": [
      "peer_reviewed_journal",
      "textbook_chapter",
      "research_database"
    ],
    "difficulty": "hard",
    "query": "Across biodiversity monitoring studies, what gaps exist between remote sensing indicators and species-level outcomes?",
    "expected_keywords": [
      "remote sensing",
      "biodiversity proxies",
      "ground truth"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q098",
    "tier": "tier_3",
    "question": "What does cross-study evidence say about long-term impacts of early-childhood interventions, and what mechanisms remain contested?",
    "expected_sources": [
      "peer_reviewed_journal",
      "meta_analysis",
      "methodology_handbook"
    ],
    "difficulty": "hard",
    "query": "What does cross-study evidence say about long-term impacts of early-childhood interventions, and what mechanisms remain contested?",
    "expected_keywords": [
      "longitudinal outcomes",
      "mechanism",
      "heterogeneity"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q099",
    "tier": "tier_3",
    "question": "Integrate results from battery chemistry papers: which degradation mechanisms most constrain fast charging?",
    "expected_sources": [
      "conference_paper",
      "preprint_server",
      "benchmark_documentation"
    ],
    "difficulty": "hard",
    "query": "Integrate results from battery chemistry papers: which degradation mechanisms most constrain fast charging?",
    "expected_keywords": [
      "lithium plating",
      "SEI",
      "thermal effects"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  },
  {
    "id": "q100",
    "tier": "tier_3",
    "question": "Across misinformation intervention studies, which debiasing strategies scale and which fail across cultures?",
    "expected_sources": [
      "peer_reviewed_journal",
      "meta_analysis",
      "methodology_handbook"
    ],
    "difficulty": "hard",
    "query": "Across misinformation intervention studies, which debiasing strategies scale and which fail across cultures?",
    "expected_keywords": [
      "prebunking",
      "fact-checking",
      "cultural context"
    ],
    "difficulty_tier": "tier_3",
    "min_citations": 3,
    "max_citations": 7
  }
]
